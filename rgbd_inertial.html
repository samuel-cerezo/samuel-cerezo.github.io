<!DOCTYPE HTML>

<html>
	<head>
		<title>Samuel Adrian Cerezo</title>
		
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>

		<!--------------------------------------------- LaTex Scripts --------------------------------------------------------->
		<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
		<script>
		MathJax = {
		  tex: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
		};
		</script>
		<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
		<!--------------------------------------------- LaTex Scripts --------------------------------------------------------->

	</head>

	<body class="is-preload">

		<div id="page-wrapper">

			<!-- Header -->
				<header id="header">
					<h1 id="logo"><a href="index.html">Home</a></h1>
					<nav id="nav">
						<ul>
							<li>
								<a href="#">Projects</a>
								<ul>
									<li><a href="rgbd_inertial.html">[2022] RGBD Inertial Flow</a></li>
									<li><a href="compressive.html">[2020] Compressive Sensing System</a></li>	
								</ul>
							</li>
							<li><a href="contact.html">Contact me</a></li>
							<li><a href="cv.html">My CV</a></li>
						</ul>
					</nav>
				</header>

			<!-- Main -->
		
				<div id="main" class="wrapper style1">
					<div class="container">
						<header class="major">
							<h2>RGBD Inertial Flow</h2>
							<p>My actual research topic</p>
						</header>

							<div class="col-8 col-12-medium imp-medium">

								<!-- Content -->
									<section id="content">
										
										<h3>Introduction</h3>
										<p>
											Scene flow is the three-dimensional motion field of points in the world, 
											just as optical flow is the two- dimensional motion field of points in an image. 
										</p>
										
										<div align="center"><a href="#" class="image"><img src="images/sliding_N_camera_poses.png" style="width: 40vw"  /></a></div>

										<h3>Optimization problem</h3>

										<p>In order to estimate the motion field we formulate an optimization problem over the state $\mathbf{x}$ for which the camera velocity consistency is imposed as well as those terms corresponding to the pre-integration of the IMU readings.
										The joint optimization problem will consist on minimizing a cost function $J(\mathbf{x})$ which is the summation of terms associated to the inertial measurements $J_{i}$ as well as to the camera measurements $J_{c}$.
										Our state estimate $\hat{\mathbf{x}}$ will be the one that minimizing the cost function $J(\mathbf{x})$.</p>
										\begin{align}
												\hat{\mathbf{x}} = min_{\mathbf{x}}  J(\mathbf{x}) = min_{\mathbf{x}}  \left(  J_{c}(\mathbf{x}) + J_{i}(\mathbf{x}) \right)
										\end{align}
										<p>
										As we add more frames, the result is a sliding window of $N$ frames moving along the camera trajectory.
										In the general case, the cost function $J(\mathbf{x})$ can be expressed compactly using as follows:
												\begin{equation}
														J(\mathbf{x})= 
															\sum_{p=i}^{i+N-1}\left(\mathbf{r}_{c_{p}}^\top{\boldsymbol\Sigma}_{c_{p}}^{-1}\mathbf{r}_{c_{p}} +  \mathbf{r}_{\Delta \mathbf{v}_{p}}^\top{\boldsymbol\Sigma}_{\Delta \mathbf{v}_{p}}^{-1} \mathbf{r}_{\Delta \mathbf{v}_{p}}\right)
															+ \mathbf{r}_{bg}^\top{\boldsymbol\Sigma}_{\boldsymbol\omega}^{-1} \mathbf{r}_{bg}
															+ \mathbf{r}_{ba}^\top{\boldsymbol\Sigma}_{\mathbf{a}}^{-1} \mathbf{r}_{ba}   
															+ \sum_{l=i}^{i+N}\mathbf{r}_{\omega_l }^\top{\boldsymbol\Sigma}_{\boldsymbol\omega}^{-1}\mathbf{r}_{\omega_l}
												\end{equation}
										and the state $\mathbf{x} \in \mathbb{R}^{6N+8}$ is defined as:
										\begin{equation}
												\mathbf{x} = \left[ {\mathbf{v}}_i^\top,{\boldsymbol\omega}_i^\top,\dots,{\mathbf{v}}_{i+N-1}^\top,{\boldsymbol\omega}_{i+N-1}^\top,{\mathbf{g}}^\top,{\mathbf{b}^g}^\top, {\mathbf{b}^a}^\top \right]^\top
										\end{equation}
										</p>

										<h3>Marginalization</h3>
										<p>Consider the case in following figure, using a 3-frames-sliding-window. When the $l$-frame comes, the optimization is done. 
										However, in order to keep a 3-frame window, when the next frame $l+1$ comes, we need to marginalize out $\mathbf{v}_i$ and $\boldsymbol{\omega}_i$.</p>
										<div align="center"><a href="#" class="image"><img src="images/grafo_marginalizacion.png" style="width: 40vw"  /></a></div>
										<p>
										The Hessian $\mathbf{H}$ contains the second derivatives of the cost function with respect to the state variables, that encodes how every state variable affects the others. 
										We denote as $\alpha$ the block of variables we would like to marginalize, and $\beta$ the block of variables we would like to keep.
										When marginalizing a set $\alpha$ of variables, we gather all factors dependent on them as well as the connected variables $\beta$. This is done by means of the \textit{Schur Complement}, which is defined in Equation (\ref{eq:schur-complement}). 
											\begin{equation}
													\mathbf{H}^* = \mathbf{H}_{\beta\beta} 
																 - \mathbf{H}_{\alpha\beta}^\top\mathbf{H}_{\alpha\alpha}^{-1}\mathbf{H}_{\alpha\beta}   
											\end{equation}
										</p>

										<h3>Experiments</h3>
										<p>
											We chose to evaluate our proposal on an extended version of the living room sequences in the ICL-NUIM dataset. 
											ICL-NUIM is a synthetic photorealistic dataset that provides ground truth poses as well as 3D scene models to benchmark reconstruction and/or localization approaches. 
											As ICL-NUIM does not provide IMU data, we fit splines to the ground truth poses to simulate continuous trajectories and simulated IMU measurements from them. 
											We also evaluated our RGB-D-inertial flow in the OpenLORIS-Scene datasets, in which data are collected in real-world indoor scenes, 
											for multiple times in each place to include natural scene changes in everyday scenarios. 
											RGB-D images and IMU measurements from a RealSense D435i are provided. 
											The ground truth trajectory was recorded by an OptiTrack MCS, that tracked artificial markers deployed on the Segway robot used to record the data.
										</p>
										Additional options:
										<ul>
											<li>1)</li>
											<li>2)</li>
											<li>3)</li>
										</ul>

										<h3>Conclusions</h3>
										
										<p>
											In this work we present a novel scene flow method that fuses RGB, depth and inertial measurements. 
											A new formulation of the joint problem was presented, which allows the fusion of visual and inertial data in the same optimization algorithm. 
											In addition to improving the general accuracy of the estimation, the joint visual-range-inertial optimization has the potential to improve the robustness of the scene flow in situations of low lighting, occlusions and poor geometry and texture. 
											We evaluated our approach on a synthetic dataset, ICL-NUIM, and on a real dataset, OpenLORIS, both publicly available. Our results quantify the improvement that inertial fusion can offer to RGB-D scene flow. 
										</p>

									</section>

							</div>

							<div class="row gtr-150">
								<div class="col-6 col-12-medium">
	
								<!-- Sidebar -->
									<section id="sidebar">

										<hr />
										<section>
											<h3>Other projects: Compressive Sensing System</h3>
											<p>...</p>
											
											<a href="compressive.html" class="image fit"><img src="images/primer_resultado.jpg" alt="" /></a>
											<footer>
												<ul class="actions">
													<li><a href="compressive.html" class="button">Learn More</a></li>
												</ul>
											</footer>
											<hr />
										</section>
									</section>
							</div>
						</div>
					</div>
				</div>

			<!-- Footer -->
				<footer id="footer">
					<ul class="icons">
						<li><a href="https://twitter.com/SamuelCerezoo/" target="_blank" class="icon brands alt fa-twitter"><span class="label">Twitter</span></a></li>
						<li><a href="https://www.linkedin.com/in/samuel-cerezo/" target="_blank" class="icon brands alt fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
						<li><a href="https://www.instagram.com/samucerezo/" target="_blank" class="icon brands alt fa-instagram"><span class="label">Instagram</span></a></li>
						<li><a href="https://github.com/samuelcerezoo/" target="_blank" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
						<li><a href="mailto: samueladriancerezo@gmail.com" class="icon solid alt fa-envelope"><span class="label">Email</span></a></li>
					</ul>
					<ul class="copyright">
						<li>&copy; Untitled. All rights reserved.</li><li>Design: HTML5 UP</a></li>
					</ul>
				</footer>

		</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.dropotron.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>